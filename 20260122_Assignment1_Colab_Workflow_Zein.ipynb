{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joezein71/AIHC-5010-Winter-2026/blob/main/20260122_Assignment1_Colab_Workflow_Zein.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0",
      "metadata": {
        "id": "0"
      },
      "source": [
        "# Assignment 1 — Colab Workflow (GitHub + Pre-commit + Submission Validation)\n",
        "\n",
        "This notebook teaches the standard workflow used throughout the course:\n",
        "\n",
        "1. Clone your team repo\n",
        "2. Install dependencies\n",
        "3. Install **pre-commit** and enable a hook to strip notebook outputs\n",
        "4. Run this notebook end-to-end\n",
        "5. Validate `predictions.csv`\n",
        "6. Commit + push + tag\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1",
        "outputId": "0f67f29a-d995-4199-d8ac-521cd043124a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "Linux-6.6.105+-x86_64-with-glibc2.35\n"
          ]
        }
      ],
      "source": [
        "# (Colab) show python and system info\n",
        "import sys, platform\n",
        "print(sys.version)\n",
        "print(platform.platform())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2",
      "metadata": {
        "id": "2"
      },
      "source": [
        "## 1) Clone Repo\n",
        "\n",
        "Login to your personal Github account, and make a fork of: https://github.com/TLKline/AIHC-5010-Winter-2026\n",
        "\n",
        "Follow setup directions for working with a PAT in GitHub (30-second guide):\n",
        "\n",
        "* Go to GitHub → Settings\n",
        "* Developer settings\n",
        "* Personal access tokens\n",
        "* Choose:\n",
        "  * Fine-Grained\n",
        "\n",
        "You can clone using HTTPS.\n",
        "\n",
        "Repo HTTPS URL (e.g., `https://github.com/TLKline/AIHC-5010-Winter-2026.git`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3",
        "outputId": "57aca92a-a27e-4555-8840-fd4ab0488089"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'student_repo' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "# TODO: Change the following to your github repo path\n",
        "repo_path = 'https://github.com/joezein71/AIHC-5010-Winter-2026.git'\n",
        "!git clone {repo_path} student_repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4",
        "outputId": "d2726660-bd53-4729-939a-7fa489c0c297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/student_repo\n",
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mpredictions.csv\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n",
            "----------\n",
            "We are at:\n",
            "/content/student_repo\n"
          ]
        }
      ],
      "source": [
        "# Move into repo\n",
        "%cd student_repo\n",
        "\n",
        "# Repo git info\n",
        "!git status\n",
        "\n",
        "# Where are we?\n",
        "print('----------')\n",
        "print('We are at:')\n",
        "!pwd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5",
      "metadata": {
        "id": "5"
      },
      "source": [
        "## 2) Install dependencies\n",
        "\n",
        "This installs whatever is in `requirements.txt`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6",
      "metadata": {
        "id": "6"
      },
      "outputs": [],
      "source": [
        "!pip -q install -r Project-1/readmit30/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7",
      "metadata": {
        "id": "7"
      },
      "source": [
        "## 3) Enable pre-commit hook to strip notebook outputs\n",
        "\n",
        "This prevents giant notebooks and reduces merge/diff pain.\n",
        "\n",
        "One-time per clone:\n",
        "- `pre-commit install`\n",
        "\n",
        "After that, every `git commit` will strip outputs from `*.ipynb`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8",
        "outputId": "6a6813e9-56a3-483f-c2d6-fc4e7cb4a9df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pre-commit installed at .git/hooks/pre-commit\n"
          ]
        }
      ],
      "source": [
        "!pip -q install pre-commit\n",
        "!pre-commit install\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9",
      "metadata": {
        "id": "9"
      },
      "source": [
        "#MAINSTART"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10",
      "metadata": {
        "id": "10"
      },
      "source": [
        "# 4) Submission Notebook (Template)\n",
        "\n",
        "Replace the baseline model with your team’s approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11",
        "outputId": "7da33c81-fc26-4d1a-a8d8-60e7659e0b04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN_PATH: Project-1/readmit30/scripts/data/public/train.csv\n",
            "DEV_PATH: Project-1/readmit30/scripts/data/public/dev.csv\n",
            "TEST_PATH: Project-1/readmit30/scripts/data/public/public_test.csv\n",
            "OUT_PATH: predictions.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "TRAIN_PATH = os.environ.get(\"TRAIN_PATH\", \"Project-1/readmit30/scripts/data/public/train.csv\")\n",
        "DEV_PATH   = os.environ.get(\"DEV_PATH\",   \"Project-1/readmit30/scripts/data/public/dev.csv\")\n",
        "TEST_PATH  = os.environ.get(\"TEST_PATH\",  \"Project-1/readmit30/scripts/data/public/public_test.csv\")\n",
        "OUT_PATH   = os.environ.get(\"OUT_PATH\",   \"predictions.csv\")\n",
        "\n",
        "print(\"TRAIN_PATH:\", TRAIN_PATH)\n",
        "print(\"DEV_PATH:\", DEV_PATH)\n",
        "print(\"TEST_PATH:\", TEST_PATH)\n",
        "print(\"OUT_PATH:\", OUT_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Also changing \"?\" and \"Unknown/Invalid\" to missing"
      ],
      "metadata": {
        "id": "EgnTAA_okp5t"
      },
      "id": "EgnTAA_okp5t"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "12",
      "metadata": {
        "id": "12"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(42)\n",
        "\n",
        "train = pd.read_csv(TRAIN_PATH, na_values=['?', 'Unknown/Invalid'])\n",
        "test = pd.read_csv(TEST_PATH, na_values=['?', 'Unknown/Invalid'])\n",
        "\n",
        "assert \"row_id\" in train.columns and \"readmit30\" in train.columns\n",
        "assert \"row_id\" in test.columns\n",
        "\n",
        "X_train = train.drop(columns=[\"readmit30\"])\n",
        "y_train = train[\"readmit30\"].astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EDA Assignment**"
      ],
      "metadata": {
        "id": "SbSZWvQMio9i"
      },
      "id": "SbSZWvQMio9i"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1- Basic dataset snapshot**\n",
        "       - Rows x colums\n",
        "       - Outcomes columns names and overall readmission rate\n",
        "       - Data types summary"
      ],
      "metadata": {
        "id": "mjFgphJ5mlkp"
      },
      "id": "mjFgphJ5mlkp"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BH7YvLI-nIxW"
      },
      "id": "BH7YvLI-nIxW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f43e677d",
        "outputId": "6a18bcd2-1771-40f9-97c3-881f90b5e910"
      },
      "source": [
        "print(f\"Dimensions of training data (train): {train.shape[0]} rows, {train.shape[1]} columns\")\n",
        "print(f\"Dimensions of training features (X_train): {X_train.shape[0]} rows, {X_train.shape[1]} columns\")\n",
        "print(f\"Dimensions of test data: {test.shape[0]} rows, {test.shape[1]} columns\")"
      ],
      "id": "f43e677d",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensions of training data (train): 65003 rows, 51 columns\n",
            "Dimensions of training features (X_train): 65003 rows, 50 columns\n",
            "Dimensions of test data: 16314 rows, 50 columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outcomes (readmission rate at 30 days)"
      ],
      "metadata": {
        "id": "h6OlIblanboM"
      },
      "id": "h6OlIblanboM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc7d2436",
        "outputId": "ae122304-42c7-4ae9-f168-b16b4176edd2"
      },
      "source": [
        "overall_readmission_rate = y_train.mean()\n",
        "print(f\"Overall Readmission Rate (readmit30): {overall_readmission_rate:.4f}\")"
      ],
      "id": "cc7d2436",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Readmission Rate (readmit30): 0.1116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Overview of Data**"
      ],
      "metadata": {
        "id": "ETCaae6z4fpN"
      },
      "id": "ETCaae6z4fpN"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oecsnovM8kvi"
      },
      "id": "oecsnovM8kvi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f59caa8",
        "outputId": "a3e644b8-f18a-4492-f40f-7d4d9ceb8322"
      },
      "source": [
        "print(\"Data types for 'weight', 'max_glu_serum', and 'A1Cresult' in X_train:\")\n",
        "X_train[['weight', 'max_glu_serum', 'A1Cresult']].info()"
      ],
      "id": "5f59caa8",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data types for 'weight', 'max_glu_serum', and 'A1Cresult' in X_train:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 65003 entries, 0 to 65002\n",
            "Data columns (total 3 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   weight         1983 non-null   float64\n",
            " 1   max_glu_serum  3419 non-null   float64\n",
            " 2   A1Cresult      10792 non-null  float64\n",
            "dtypes: float64(3)\n",
            "memory usage: 1.5 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "f63ec547",
        "outputId": "945fe229-a448-4ee6-c8fa-052063f83f9b"
      },
      "source": [
        "print(\"Head of X_train (training features):\")\n",
        "display(X_train.head())"
      ],
      "id": "f63ec547",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Head of X_train (training features):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   encounter_id  patient_nbr       race  gender      age weight  \\\n",
              "0       2278392      8222157  Caucasian  Female   [0-10)    NaN   \n",
              "1        149190     55629189  Caucasian  Female  [10-20)    NaN   \n",
              "2         16680     42519267  Caucasian    Male  [40-50)    NaN   \n",
              "3         35754     82637451  Caucasian    Male  [50-60)    NaN   \n",
              "4         63768    114882984  Caucasian    Male  [70-80)    NaN   \n",
              "\n",
              "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
              "0                  6                        25                    1   \n",
              "1                  1                         1                    7   \n",
              "2                  1                         1                    7   \n",
              "3                  2                         1                    2   \n",
              "4                  1                         1                    7   \n",
              "\n",
              "   time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
              "0                 1  ...          No      No                   No   \n",
              "1                 3  ...          No      Up                   No   \n",
              "2                 1  ...          No  Steady                   No   \n",
              "3                 3  ...          No  Steady                   No   \n",
              "4                 5  ...          No      No                   No   \n",
              "\n",
              "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
              "0                   No                        No                       No   \n",
              "1                   No                        No                       No   \n",
              "2                   No                        No                       No   \n",
              "3                   No                        No                       No   \n",
              "4                   No                        No                       No   \n",
              "\n",
              "   metformin-pioglitazone  change diabetesMed   row_id  \n",
              "0                      No      No          No  2278392  \n",
              "1                      No      Ch         Yes   149190  \n",
              "2                      No      Ch         Yes    16680  \n",
              "3                      No      No         Yes    35754  \n",
              "4                      No      No         Yes    63768  \n",
              "\n",
              "[5 rows x 50 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09bd1477-25bb-45ac-95e3-9bbd362331a8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>encounter_id</th>\n",
              "      <th>patient_nbr</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "      <th>admission_type_id</th>\n",
              "      <th>discharge_disposition_id</th>\n",
              "      <th>admission_source_id</th>\n",
              "      <th>time_in_hospital</th>\n",
              "      <th>...</th>\n",
              "      <th>citoglipton</th>\n",
              "      <th>insulin</th>\n",
              "      <th>glyburide-metformin</th>\n",
              "      <th>glipizide-metformin</th>\n",
              "      <th>glimepiride-pioglitazone</th>\n",
              "      <th>metformin-rosiglitazone</th>\n",
              "      <th>metformin-pioglitazone</th>\n",
              "      <th>change</th>\n",
              "      <th>diabetesMed</th>\n",
              "      <th>row_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2278392</td>\n",
              "      <td>8222157</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>[0-10)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2278392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>149190</td>\n",
              "      <td>55629189</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>[10-20)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>Up</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>149190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16680</td>\n",
              "      <td>42519267</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Male</td>\n",
              "      <td>[40-50)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>16680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35754</td>\n",
              "      <td>82637451</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Male</td>\n",
              "      <td>[50-60)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>35754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>63768</td>\n",
              "      <td>114882984</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Male</td>\n",
              "      <td>[70-80)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>63768</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 50 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09bd1477-25bb-45ac-95e3-9bbd362331a8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-09bd1477-25bb-45ac-95e3-9bbd362331a8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-09bd1477-25bb-45ac-95e3-9bbd362331a8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "3126589f",
        "outputId": "5e78478c-1ead-450f-dffa-c1bf87bbea91"
      },
      "source": [
        "print(\"\\nHead of test (testing dataset):\")\n",
        "display(test.head())"
      ],
      "id": "3126589f",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Head of test (testing dataset):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   encounter_id  patient_nbr             race  gender      age weight  \\\n",
              "0     103521306     11032596        Caucasian  Female  [80-90)    NaN   \n",
              "1     127919112     88003062        Caucasian    Male  [30-40)    NaN   \n",
              "2     233245326     41356647        Caucasian  Female  [60-70)    NaN   \n",
              "3     236785056     98486064        Caucasian  Female  [50-60)    NaN   \n",
              "4     131110896    104962536  AfricanAmerican    Male  [60-70)    NaN   \n",
              "\n",
              "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
              "0                  1                         3                    6   \n",
              "1                  8                         1                    7   \n",
              "2                  3                         3                    1   \n",
              "3                  6                         1                   17   \n",
              "4                  1                         1                    7   \n",
              "\n",
              "   time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
              "0                 4  ...          No  Steady                   No   \n",
              "1                 1  ...          No      Up                   No   \n",
              "2                 3  ...          No      No                   No   \n",
              "3                 9  ...          No      Up                   No   \n",
              "4                 3  ...          No      No                   No   \n",
              "\n",
              "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
              "0                   No                        No                       No   \n",
              "1                   No                        No                       No   \n",
              "2                   No                        No                       No   \n",
              "3                   No                        No                       No   \n",
              "4                   No                        No                       No   \n",
              "\n",
              "   metformin-pioglitazone  change diabetesMed     row_id  \n",
              "0                      No      No         Yes  103521306  \n",
              "1                      No      Ch         Yes  127919112  \n",
              "2                      No      No          No  233245326  \n",
              "3                      No      Ch         Yes  236785056  \n",
              "4                      No      No          No  131110896  \n",
              "\n",
              "[5 rows x 50 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b22380d9-08f6-4d75-9d4d-6d9f1547d8f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>encounter_id</th>\n",
              "      <th>patient_nbr</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "      <th>admission_type_id</th>\n",
              "      <th>discharge_disposition_id</th>\n",
              "      <th>admission_source_id</th>\n",
              "      <th>time_in_hospital</th>\n",
              "      <th>...</th>\n",
              "      <th>citoglipton</th>\n",
              "      <th>insulin</th>\n",
              "      <th>glyburide-metformin</th>\n",
              "      <th>glipizide-metformin</th>\n",
              "      <th>glimepiride-pioglitazone</th>\n",
              "      <th>metformin-rosiglitazone</th>\n",
              "      <th>metformin-pioglitazone</th>\n",
              "      <th>change</th>\n",
              "      <th>diabetesMed</th>\n",
              "      <th>row_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>103521306</td>\n",
              "      <td>11032596</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>[80-90)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>Steady</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>103521306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>127919112</td>\n",
              "      <td>88003062</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Male</td>\n",
              "      <td>[30-40)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>Up</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>127919112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>233245326</td>\n",
              "      <td>41356647</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>[60-70)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>233245326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>236785056</td>\n",
              "      <td>98486064</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>Female</td>\n",
              "      <td>[50-60)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>9</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>Up</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Ch</td>\n",
              "      <td>Yes</td>\n",
              "      <td>236785056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>131110896</td>\n",
              "      <td>104962536</td>\n",
              "      <td>AfricanAmerican</td>\n",
              "      <td>Male</td>\n",
              "      <td>[60-70)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>131110896</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 50 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b22380d9-08f6-4d75-9d4d-6d9f1547d8f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b22380d9-08f6-4d75-9d4d-6d9f1547d8f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b22380d9-08f6-4d75-9d4d-6d9f1547d8f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Types (numeric vs. categorical)\n",
        " - change the following covariates to object variable"
      ],
      "metadata": {
        "id": "La2Byexdn3Ga"
      },
      "id": "La2Byexdn3Ga"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aac8d403",
        "outputId": "15fc67c8-1d12-470d-8142-246e591e2579"
      },
      "source": [
        "columns_to_convert = ['encounter_id', 'patient_nbr', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id', 'row_id']\n",
        "\n",
        "for col in columns_to_convert:\n",
        "    if col in X_train.columns:\n",
        "        X_train[col] = X_train[col].astype('object')\n",
        "    if col in test.columns:\n",
        "        test[col] = test[col].astype('object')\n",
        "\n",
        "print(\"Data types after conversion (X_train):\")\n",
        "X_train.info()"
      ],
      "id": "aac8d403",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data types after conversion (X_train):\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 65003 entries, 0 to 65002\n",
            "Data columns (total 50 columns):\n",
            " #   Column                    Non-Null Count  Dtype \n",
            "---  ------                    --------------  ----- \n",
            " 0   encounter_id              65003 non-null  object\n",
            " 1   patient_nbr               65003 non-null  object\n",
            " 2   race                      63532 non-null  object\n",
            " 3   gender                    65001 non-null  object\n",
            " 4   age                       65003 non-null  object\n",
            " 5   weight                    1985 non-null   object\n",
            " 6   admission_type_id         65003 non-null  object\n",
            " 7   discharge_disposition_id  65003 non-null  object\n",
            " 8   admission_source_id       65003 non-null  object\n",
            " 9   time_in_hospital          65003 non-null  int64 \n",
            " 10  payer_code                39270 non-null  object\n",
            " 11  medical_specialty         33194 non-null  object\n",
            " 12  num_lab_procedures        65003 non-null  int64 \n",
            " 13  num_procedures            65003 non-null  int64 \n",
            " 14  num_medications           65003 non-null  int64 \n",
            " 15  number_outpatient         65003 non-null  int64 \n",
            " 16  number_emergency          65003 non-null  int64 \n",
            " 17  number_inpatient          65003 non-null  int64 \n",
            " 18  diag_1                    64990 non-null  object\n",
            " 19  diag_2                    64785 non-null  object\n",
            " 20  diag_3                    64099 non-null  object\n",
            " 21  number_diagnoses          65003 non-null  int64 \n",
            " 22  max_glu_serum             3419 non-null   object\n",
            " 23  A1Cresult                 10792 non-null  object\n",
            " 24  metformin                 65003 non-null  object\n",
            " 25  repaglinide               65003 non-null  object\n",
            " 26  nateglinide               65003 non-null  object\n",
            " 27  chlorpropamide            65003 non-null  object\n",
            " 28  glimepiride               65003 non-null  object\n",
            " 29  acetohexamide             65003 non-null  object\n",
            " 30  glipizide                 65003 non-null  object\n",
            " 31  glyburide                 65003 non-null  object\n",
            " 32  tolbutamide               65003 non-null  object\n",
            " 33  pioglitazone              65003 non-null  object\n",
            " 34  rosiglitazone             65003 non-null  object\n",
            " 35  acarbose                  65003 non-null  object\n",
            " 36  miglitol                  65003 non-null  object\n",
            " 37  troglitazone              65003 non-null  object\n",
            " 38  tolazamide                65003 non-null  object\n",
            " 39  examide                   65003 non-null  object\n",
            " 40  citoglipton               65003 non-null  object\n",
            " 41  insulin                   65003 non-null  object\n",
            " 42  glyburide-metformin       65003 non-null  object\n",
            " 43  glipizide-metformin       65003 non-null  object\n",
            " 44  glimepiride-pioglitazone  65003 non-null  object\n",
            " 45  metformin-rosiglitazone   65003 non-null  object\n",
            " 46  metformin-pioglitazone    65003 non-null  object\n",
            " 47  change                    65003 non-null  object\n",
            " 48  diabetesMed               65003 non-null  object\n",
            " 49  row_id                    65003 non-null  object\n",
            "dtypes: int64(8), object(42)\n",
            "memory usage: 24.8+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25da82a2"
      },
      "source": [
        "print(\"Summary Statistics for Numeric Columns in X_train:\")\n",
        "\n",
        "# Select only numeric columns\n",
        "numeric_columns = X_train.select_dtypes(include=np.number)\n",
        "\n",
        "display(numeric_columns.describe())"
      ],
      "id": "25da82a2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08b31a68"
      },
      "source": [
        "print(\"Data Types and Non-Null Counts for X_train:\")\n",
        "X_train.info()"
      ],
      "id": "08b31a68",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e05a29a"
      },
      "source": [
        "print(\"Variable Type Stratification:\")\n",
        "print(\"-------------------------------\")\n",
        "\n",
        "continuous_vars = []\n",
        "integer_vars = []\n",
        "categorical_vars = []\n",
        "\n",
        "for col in X_train.columns:\n",
        "    dtype = X_train[col].dtype\n",
        "    if pd.api.types.is_float_dtype(dtype): # Check for float types first for continuous\n",
        "        continuous_vars.append(col)\n",
        "    elif pd.api.types.is_integer_dtype(dtype): # Check for integer types\n",
        "        integer_vars.append(col)\n",
        "    elif pd.api.types.is_object_dtype(dtype) or pd.api.types.is_categorical_dtype(dtype): # Check for object or categorical types\n",
        "        categorical_vars.append(col)\n",
        "    # We can add more specific checks for datetime if necessary, but none are identified here\n",
        "\n",
        "print(\"Continuous Variables:\")\n",
        "if continuous_vars: print(continuous_vars)\n",
        "else: print(\"None\")\n",
        "\n",
        "print(\"\\nInteger Variables:\")\n",
        "if integer_vars: print(integer_vars)\n",
        "else: print(\"None\")\n",
        "\n",
        "print(\"\\nCategorical Variables:\")\n",
        "if categorical_vars: print(categorical_vars)\n",
        "else: print(\"None\")"
      ],
      "id": "5e05a29a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Summary statistics for continuous variables"
      ],
      "metadata": {
        "id": "1Ae-JlD2pVak"
      },
      "id": "1Ae-JlD2pVak"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae3e5f6e"
      },
      "source": [
        "print(\"Summary Statistics for Numeric Columns in X_train:\")\n",
        "numeric_columns_train = X_train.select_dtypes(include=np.number)\n",
        "display(numeric_columns_train.describe())"
      ],
      "id": "ae3e5f6e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "572d8b20"
      },
      "source": [
        "print(\"\\nSummary Statistics for Numeric Columns in test data:\")\n",
        "numeric_columns_test = test.select_dtypes(include=np.number)\n",
        "display(numeric_columns_test.describe())"
      ],
      "id": "572d8b20",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Summary Statistics for categorical variables in both testing and training datasets"
      ],
      "metadata": {
        "id": "99YHbA-hpcQX"
      },
      "id": "99YHbA-hpcQX"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc5d941e"
      },
      "source": [
        "print(\"\\nSummary Statistics for Categorical Columns in X_train:\")\n",
        "categorical_columns_train = X_train.select_dtypes(include='object')\n",
        "display(categorical_columns_train.describe())"
      ],
      "id": "cc5d941e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e60777de"
      },
      "source": [
        "print(\"\\nSummary Statistics for Categorical Columns in test data:\")\n",
        "categorical_columns_test = test.select_dtypes(include='object')\n",
        "display(categorical_columns_test.describe())"
      ],
      "id": "e60777de",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2- Missingness Audit**\n",
        "      1 - A table of missingness per column: count missing and % missing, sorted high to low\n",
        "      2 - A bar plot of the top 15 columns by % missing.\n",
        "      3 - A short list:\n",
        "          - 3 columns with acceptable missingness (<5%)\n",
        "          - 3 columns with problematic missingness (>30%) and your recommended action"
      ],
      "metadata": {
        "id": "NyG5UHLuqpQa"
      },
      "id": "NyG5UHLuqpQa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1- Table of missingness per column: Count missing and % missing, sorted high to low"
      ],
      "metadata": {
        "id": "RN-rLwrvjtDB"
      },
      "id": "RN-rLwrvjtDB"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values in X_train:\")\n",
        "missing_train = X_train.isnull().sum()\n",
        "missing_train = missing_train[missing_train > 0].sort_values(ascending=False)\n",
        "if not missing_train.empty:\n",
        "    missing_train_df = pd.DataFrame(missing_train, columns=['Missing Count'])\n",
        "    missing_train_df['% Missing'] = (missing_train_df['Missing Count'] / len(X_train)) * 100\n",
        "    display(missing_train_df)\n",
        "else:\n",
        "    print(\"No missing values in X_train.\")\n",
        "\n",
        "print(\"\\nMissing values in test:\")\n",
        "missing_test = test.isnull().sum()\n",
        "missing_test = missing_test[missing_test > 0].sort_values(ascending=False)\n",
        "if not missing_test.empty:\n",
        "    missing_test_df = pd.DataFrame(missing_test, columns=['Missing Count'])\n",
        "    missing_test_df['% Missing'] = (missing_test_df['Missing Count'] / len(test)) * 100\n",
        "    display(missing_test_df)\n",
        "else:\n",
        "    print(\"No missing values in test.\")"
      ],
      "metadata": {
        "id": "oKKpLYc9joqd"
      },
      "id": "oKKpLYc9joqd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 - A bar plot of the top 15 columns by % missing:\n",
        "  - ***Only the first 10 variables in the plot include missing value. The next 5 variables were added to the plot although they do not include missing values***"
      ],
      "metadata": {
        "id": "tFsz-_LAsnlq"
      },
      "id": "tFsz-_LAsnlq"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6f6a0a1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "if 'missing_train_df' in locals() and not missing_train_df.empty:\n",
        "    # Get columns with 0% missingness\n",
        "    zero_missing_cols = X_train.columns[X_train.isnull().sum() == 0].tolist()\n",
        "\n",
        "    # Exclude columns already in missing_train_df's index\n",
        "    zero_missing_cols = [col for col in zero_missing_cols if col not in missing_train_df.index]\n",
        "\n",
        "    # Select the first 5 of these zero-missing columns (or fewer if less than 5 are available)\n",
        "    additional_cols_for_plot = zero_missing_cols[:5]\n",
        "\n",
        "    # Create a DataFrame for these additional columns with 0% missing\n",
        "    if additional_cols_for_plot:\n",
        "        additional_missing_df = pd.DataFrame({\n",
        "            'Missing Count': [0] * len(additional_cols_for_plot),\n",
        "            '% Missing': [0.0] * len(additional_cols_for_plot)\n",
        "        }, index=additional_cols_for_plot)\n",
        "\n",
        "        # Combine the original missing_train_df with the additional zero-missing columns\n",
        "        combined_missing_df = pd.concat([missing_train_df, additional_missing_df])\n",
        "    else:\n",
        "        combined_missing_df = missing_train_df\n",
        "\n",
        "    # Select the top 15 entries from the combined DataFrame\n",
        "    top_15_for_plot = combined_missing_df.head(15)\n",
        "\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    sns.barplot(x=top_15_for_plot.index, y=top_15_for_plot['% Missing'], palette='viridis', hue=top_15_for_plot.index, legend=False)\n",
        "    plt.title('Top Variables by Percentage Missingness in Training Data (including 0% missing)')\n",
        "    plt.xlabel('Variable')\n",
        "    plt.ylabel('Percentage Missing (%)')\n",
        "    plt.xticks(rotation=60, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"missing_train_df not found or is empty. Please run the missingness audit cells first.\")"
      ],
      "id": "e6f6a0a1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 - List of 3 variables with missingness <5% and 3 variables with missingness >30%\n",
        "\n",
        "      - All variables with missingness should be investigated to assess whether the is evidence that values are \"missing not at random (MNAR)\" vs. \"missing at random (MAR)\" .\n",
        "      - Values MAR with missingness < 5% should be imputed preferably using multiple imputation with methods such as \"multiple imputation by chained equations (MICE)\".\n",
        "      - imputation should not be used if missingness is not at random, or if missingness is >30%.\n",
        "    "
      ],
      "metadata": {
        "id": "ag7F4mMUu08_"
      },
      "id": "ag7F4mMUu08_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c6dcf6f"
      },
      "source": [
        "print(\"Summary of Variables by Missingness:\")\n",
        "print(\"------------------------------------\")\n",
        "\n",
        "if 'missing_train_df' in locals() and not missing_train_df.empty:\n",
        "    # Variables with <5% missingness\n",
        "    low_missing_vars = missing_train_df[missing_train_df['% Missing'] < 5].head(3)\n",
        "\n",
        "    # Variables with >30% missingness\n",
        "    high_missing_vars = missing_train_df[missing_train_df['% Missing'] > 30].head(3)\n",
        "\n",
        "    print(\"\\nVariables with <5% Missingness:\")\n",
        "    if not low_missing_vars.empty:\n",
        "        display(low_missing_vars)\n",
        "    else:\n",
        "        print(\"None found.\")\n",
        "\n",
        "    print(\"\\nVariables with >30% Missingness:\")\n",
        "    if not high_missing_vars.empty:\n",
        "        display(high_missing_vars)\n",
        "    else:\n",
        "        print(\"None found.\")\n",
        "else:\n",
        "    print(\"missing_train_df not found or is empty. Please run the missingness audit cells first.\")"
      ],
      "id": "6c6dcf6f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9619d1f"
      },
      "source": [
        "2- What is the overall value distribution for some specific variables like 'gender', 'race', 'age', and 'diag_1'?"
      ],
      "id": "b9619d1f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7aba09e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "variables_to_plot = ['gender', 'race', 'age', 'diag_1']\n",
        "\n",
        "for var in variables_to_plot:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    if var == 'diag_1': # Handle potential large number of unique values for diag_1\n",
        "        top_n = X_train[var].value_counts().nlargest(20)\n",
        "        sns.barplot(x=top_n.index, y=top_n.values)\n",
        "        plt.title(f'Top 20 Value Distribution for {var} in X_train')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "    else:\n",
        "        sns.countplot(data=X_train, x=var)\n",
        "        plt.title(f'Value Distribution for {var} in X_train')\n",
        "    plt.xlabel(var)\n",
        "    plt.ylabel('Count')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "id": "d7aba09e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2 - Is missingness related to the readmission outcomes?**"
      ],
      "metadata": {
        "id": "DmdAhFnlmTg1"
      },
      "id": "DmdAhFnlmTg1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22697cfc"
      },
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "print(\"Analyzing missingness in relation to readmission outcomes...\")\n",
        "\n",
        "# Get columns with missing values from X_train\n",
        "missing_cols_train = X_train.columns[X_train.isnull().any()].tolist()\n",
        "\n",
        "if not missing_cols_train:\n",
        "    print(\"No missing values found in X_train for analysis.\")\n",
        "else:\n",
        "    results = []\n",
        "    for col in missing_cols_train:\n",
        "        # Create a temporary DataFrame with the column, its missing indicator, and the target variable\n",
        "        temp_df = pd.DataFrame({\n",
        "            'is_missing': X_train[col].isnull(),\n",
        "            'readmit30': y_train\n",
        "        })\n",
        "\n",
        "        # Calculate counts for contingency table\n",
        "        missing_readmit_count = temp_df[(temp_df['is_missing'] == True) & (temp_df['readmit30'] == 1)].shape[0]\n",
        "        missing_non_readmit_count = temp_df[(temp_df['is_missing'] == True) & (temp_df['readmit30'] == 0)].shape[0]\n",
        "        non_missing_readmit_count = temp_df[(temp_df['is_missing'] == False) & (temp_df['readmit30'] == 1)].shape[0]\n",
        "        non_missing_non_readmit_count = temp_df[(temp_df['is_missing'] == False) & (temp_df['readmit30'] == 0)].shape[0]\n",
        "\n",
        "        # Calculate the average readmit30 rate for missing and non-missing groups\n",
        "        missing_readmit_rate = temp_df[temp_df['is_missing'] == True]['readmit30'].mean()\n",
        "        non_missing_readmit_rate = temp_df[temp_df['is_missing'] == False]['readmit30'].mean()\n",
        "\n",
        "        p_value = np.nan\n",
        "        # Perform Chi-squared test if there are enough observations in each category\n",
        "        if (missing_readmit_count + missing_non_readmit_count > 0) and \\\n",
        "           (non_missing_readmit_count + non_missing_non_readmit_count > 0) and \\\n",
        "           (missing_readmit_count + non_missing_readmit_count > 0) and \\\n",
        "           (missing_non_readmit_count + non_missing_non_readmit_count > 0):\n",
        "            contingency_table = [\n",
        "                [missing_readmit_count, missing_non_readmit_count],\n",
        "                [non_missing_readmit_count, non_missing_non_readmit_count]\n",
        "            ]\n",
        "            # Only perform chi2_contingency if all expected frequencies are >= 5\n",
        "            # This is a common rule of thumb for the validity of the chi-squared test\n",
        "            try:\n",
        "                chi2, p, _, expected = stats.chi2_contingency(contingency_table)\n",
        "                if np.all(expected >= 5):\n",
        "                    p_value = p\n",
        "            except ValueError: # Occurs if table dimensions are zero or contain NaNs\n",
        "                pass\n",
        "\n",
        "        results.append({\n",
        "            'Column': col,\n",
        "            'Missing Readmit Rate': missing_readmit_rate,\n",
        "            'Non-Missing Readmit Rate': non_missing_readmit_rate,\n",
        "            'P-value': p_value\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    display(results_df.sort_values(by='Missing Readmit Rate', ascending=False))\n",
        "\n",
        "    print(\"\\nInterpretation: If 'Missing Readmit Rate' is significantly different from 'Non-Missing Readmit Rate' for a given column, then missingness in that column might be related to readmission outcomes. A small P-value (e.g., < 0.05) suggests that the observed difference is statistically significant.\")"
      ],
      "id": "22697cfc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e86e795"
      },
      "source": [
        "The table above shows the readmission rates when a particular feature is missing versus when it is present. A substantial difference between these two rates could indicate that the missingness itself provides information about the readmission outcome. For instance, if the 'Missing Readmit Rate' for a column is much higher than its 'Non-Missing Readmit Rate', it suggests that patients for whom that data point is absent might have a higher propensity for readmission. This can be a form of *informative missingness*."
      ],
      "id": "6e86e795"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - Is missingness related to outcomes? Analysis of 3 specific variables with missingness >15%"
      ],
      "metadata": {
        "id": "gnCAVntZxe1_"
      },
      "id": "gnCAVntZxe1_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab04fa4b"
      },
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "print(\"Analyzing readmission rates based on missingness indicators:\")\n",
        "\n",
        "variables_to_analyze = ['payer_code', 'medical_specialty', 'A1Cresult']\n",
        "\n",
        "results_missing_indicators = []\n",
        "\n",
        "for col in variables_to_analyze:\n",
        "    # Create the binary indicator for missingness\n",
        "    X_train[f'is_missing_{col}'] = X_train[col].isnull().astype(int)\n",
        "\n",
        "    # Calculate counts for contingency table\n",
        "    missing_readmit_count = y_train[X_train[f'is_missing_{col}'] == 1].sum()\n",
        "    missing_non_readmit_count = (X_train[f'is_missing_{col}'] == 1).sum() - missing_readmit_count\n",
        "    non_missing_readmit_count = y_train[X_train[f'is_missing_{col}'] == 0].sum()\n",
        "    non_missing_non_readmit_count = (X_train[f'is_missing_{col}'] == 0).sum() - non_missing_readmit_count\n",
        "\n",
        "    # Calculate readmission rate for missing vs. not missing\n",
        "    readmit_rate_missing = y_train[X_train[f'is_missing_{col}'] == 1].mean()\n",
        "    readmit_rate_not_missing = y_train[X_train[f'is_missing_{col}'] == 0].mean()\n",
        "\n",
        "    p_value = np.nan\n",
        "    # Perform Chi-squared test if there are enough observations in each category\n",
        "    if (missing_readmit_count + missing_non_readmit_count > 0) and \\\n",
        "       (non_missing_readmit_count + non_missing_non_readmit_count > 0) and \\\n",
        "       (missing_readmit_count + non_missing_readmit_count > 0) and \\\n",
        "       (missing_non_readmit_count + non_missing_non_readmit_count > 0):\n",
        "        contingency_table = [\n",
        "            [missing_readmit_count, missing_non_readmit_count],\n",
        "            [non_missing_readmit_count, non_missing_non_readmit_count]\n",
        "        ]\n",
        "        try:\n",
        "            chi2, p, _, expected = stats.chi2_contingency(contingency_table)\n",
        "            # Common rule of thumb for chi-squared validity: all expected frequencies >= 5\n",
        "            if np.all(expected >= 5):\n",
        "                p_value = p\n",
        "        except ValueError: # Occurs if table dimensions are zero or contain NaNs\n",
        "            pass\n",
        "\n",
        "    results_missing_indicators.append({\n",
        "        'Variable': col,\n",
        "        'Readmission Rate (Missing)': readmit_rate_missing,\n",
        "        'Readmission Rate (Not Missing)': non_missing_readmit_rate,\n",
        "        'P-value': p_value\n",
        "    })\n",
        "\n",
        "results_df_indicators = pd.DataFrame(results_missing_indicators)\n",
        "display(results_df_indicators)\n",
        "\n",
        "print(\"\\nInterpretation: A significant difference between 'Readmission Rate (Missing)' and 'Readmission Rate (Not Missing)' for a variable suggests that the missingness itself might be an important predictor. A small P-value (e.g., < 0.05) suggests that the observed difference is statistically significant.\")\n",
        "\n",
        "# Drop the temporary indicator columns to keep X_train clean for subsequent steps, if any.\n",
        "# Or keep them if they are intended for feature engineering.\n",
        "for col in variables_to_analyze:\n",
        "    X_train = X_train.drop(columns=[f'is_missing_{col}'])"
      ],
      "id": "ab04fa4b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *A significant difference (p< 0.05) between 'Readmission Rate (Missing)' and 'Readmission Rate (Not Missing)' for a variable suggests that the missingness itself might be an important predictor for readmission.*"
      ],
      "metadata": {
        "id": "2K9tp90Dy8As"
      },
      "id": "2K9tp90Dy8As"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4- Minimal data quality check**\n",
        "     1- Dublicates\n",
        "     2- Outliers / Validity\n",
        "     3- leakage screen"
      ],
      "metadata": {
        "id": "n4_7cbT40iHn"
      },
      "id": "n4_7cbT40iHn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d75481d1"
      },
      "source": [
        "# **4- Minimal data quality check**\n",
        "     1- Dublicates\n",
        "     2- Outliers / Validity\n",
        "     3- leakage screen"
      ],
      "id": "d75481d1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.1 Duplicates**"
      ],
      "metadata": {
        "id": "eLZyDstS1g3t"
      },
      "id": "eLZyDstS1g3t"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yspn7RaF1nrI"
      },
      "id": "Yspn7RaF1nrI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.1 Description of the types of variables in the data"
      ],
      "metadata": {
        "id": "iSWuNY6bmATf"
      },
      "id": "iSWuNY6bmATf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13",
      "metadata": {
        "id": "13"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "# TODO: Add any new imports for your own method here\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "method = 4\n",
        "\n",
        "cat_cols = [c for c in X_train.columns if X_train[c].dtype == \"object\"]\n",
        "num_cols = [c for c in X_train.columns if c not in cat_cols]\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))]), num_cols),\n",
        "        (\"cat\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "                          (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))]), cat_cols),\n",
        "    ],\n",
        ")\n",
        "\n",
        "if method==1:\n",
        "    # Use logistic regression model\n",
        "    clf = Pipeline([\n",
        "        (\"preprocess\", preprocess),\n",
        "        (\"model\", LogisticRegression(max_iter=200)),\n",
        "    ])\n",
        "\n",
        "if method==2:\n",
        "    # Use logistic regression model\n",
        "    clf = Pipeline([\n",
        "        (\"preprocess\", preprocess),\n",
        "        (\"model\", LogisticRegression(max_iter=200,class_weight='balanced')),\n",
        "    ])\n",
        "\n",
        "if method==3:\n",
        "    # Use SVC (i.e. SVM model)\n",
        "    clf = Pipeline(\n",
        "        [\n",
        "            (\"preprocess\", preprocess),\n",
        "            (\"scaler\", StandardScaler(with_mean=False)), # Add StandardScaler here\n",
        "            (\"model\", SVC(gamma=\"auto\",max_iter=1000,probability=True)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "if method == 4:\n",
        "    # Preprocess for HGB: ordinal-encode categories (HGB needs numeric inputs)\n",
        "    preprocess_hgb = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", Pipeline([\n",
        "                (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "            ]), num_cols),\n",
        "            (\"cat\", Pipeline([\n",
        "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "                (\"ord\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)),\n",
        "            ]), cat_cols),\n",
        "        ],\n",
        "        remainder=\"drop\",\n",
        "    )\n",
        "\n",
        "    clf = Pipeline([\n",
        "        (\"preprocess\", preprocess_hgb),\n",
        "        (\"model\", HistGradientBoostingClassifier(\n",
        "            max_depth=6,\n",
        "            learning_rate=0.05,\n",
        "            max_iter=300,\n",
        "            l2_regularization=1.0,\n",
        "            early_stopping=True,\n",
        "            random_state=42,\n",
        "            class_weight='balanced',\n",
        "        )),\n",
        "    ])\n",
        "\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14",
      "metadata": {
        "id": "14"
      },
      "outputs": [],
      "source": [
        "p_test = clf.predict_proba(test)[:, 1]\n",
        "pred = pd.DataFrame({\"row_id\": test[\"row_id\"].astype(int), \"prob_readmit30\": p_test.astype(float)})\n",
        "pred.to_csv(OUT_PATH, index=False)\n",
        "pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15",
      "metadata": {
        "id": "15"
      },
      "outputs": [],
      "source": [
        "# Validate output format (required for students before tagging)\n",
        "!python Project-1/readmit30/scripts/validate_submission.py --pred {OUT_PATH} --test {TEST_PATH}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16",
      "metadata": {
        "id": "16"
      },
      "outputs": [],
      "source": [
        "# Calculate metrics for the dev set\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dev = pd.read_csv(DEV_PATH)\n",
        "\n",
        "X_dev = dev.drop(columns=[\"readmit30\"])\n",
        "y_dev = dev[\"readmit30\"].astype(int)\n",
        "\n",
        "# Calculate metrics\n",
        "y_true = y_dev.astype(int)\n",
        "y_pred = clf.predict_proba(X_dev)[:, 1]\n",
        "\n",
        "auroc = roc_auc_score(y_true, y_pred)\n",
        "auprc = average_precision_score(y_true, y_pred)\n",
        "brier = brier_score_loss(y_true, y_pred)\n",
        "\n",
        "print(f'AUROC: {auroc:.4f}')\n",
        "print(f'AUPRC: {auprc:.4f}')\n",
        "print(f'Brier Score: {brier:.4f}')\n",
        "\n",
        "# Create figures\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Histogram of predicted probabilities\n",
        "plt.hist(y_pred, bins=20, alpha=0.7, label='Predicted Probabilities')\n",
        "plt.title('Histogram of Predicted Probabilities')\n",
        "plt.xlabel('Probability')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Scatter plot of true vs predicted\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_true, y_pred, alpha=0.5, label='True vs Predicted')\n",
        "plt.title('True vs Predicted Probabilities')\n",
        "plt.xlabel('True Labels')\n",
        "plt.ylabel('Predicted Probabilities')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Create ROC Curve\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fpr, tpr, label=f'AUROC = {auroc:.4f}')\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
        "plt.title('ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Create Precision-Recall Curve\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(recall, precision, label=f'AUPRC = {auprc:.4f}')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Create Confusion Matrix Heatmap\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "threshold = 0.5  # Default threshold for binary classification\n",
        "y_pred_binary = (y_pred >= threshold).astype(int)\n",
        "cm = confusion_matrix(y_true, y_pred_binary)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Readmit', 'Readmit'], yticklabels=['No Readmit', 'Readmit'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17",
      "metadata": {
        "id": "17"
      },
      "source": [
        "#MAINEND"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18",
      "metadata": {
        "id": "18"
      },
      "source": [
        "## 5) Validate the predictions file format\n",
        "\n",
        "This checks:\n",
        "- required columns\n",
        "- probabilities in [0, 1]\n",
        "- row_ids match the test file\n",
        "\n",
        "It assumes the submission notebook wrote `predictions.csv` in the repo root.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19",
      "metadata": {
        "id": "19"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "pred_path = Path(\"predictions.csv\")\n",
        "test_path = Path(\"Project-1/readmit30/scripts/data/public/public_test.csv\")\n",
        "\n",
        "if not pred_path.exists():\n",
        "    print(\"predictions.csv not found. Run notebooks/submission.ipynb first.\")\n",
        "else:\n",
        "    !python Project-1/readmit30/scripts/validate_submission.py --pred predictions.csv --test Project-1/readmit30/scripts/data/public/public_test.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20",
      "metadata": {
        "id": "20"
      },
      "source": [
        "## 6) Commit + push + tag\n",
        "\n",
        "You will:\n",
        "- add changes\n",
        "- commit (pre-commit hook runs here)\n",
        "- push\n",
        "- tag a milestone (example: `milestone_wk3`) and push tags\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21",
      "metadata": {
        "id": "21"
      },
      "source": [
        "You will need a Personal Access Token (PAT) for the following step. See instructions above."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Colab -> GitHub commit/push for a specific notebook path (PAT auth) ====\n",
        "# What this does:\n",
        "#  1) clones the repo into the Colab VM\n",
        "#  2) overwrites the target notebook file with the *currently open* Colab notebook\n",
        "#  3) commits the change\n",
        "#  4) asks you for a GitHub PAT and pushes to the target branch\n",
        "#  5) (optional) creates a git tag and pushes the tag\n",
        "#\n",
        "# Notes:\n",
        "#  - PAT is read via getpass (not echoed). It is only used for this runtime session.\n",
        "#  - This overwrites the file at TARGET_REL with the *current Colab notebook contents*.\n",
        "\n",
        "import os\n",
        "import json\n",
        "import subprocess\n",
        "import getpass\n",
        "from google.colab import _message\n",
        "\n",
        "# ==========================\n",
        "# START USER-EDITABLE SETTINGS\n",
        "# ==========================\n",
        "# Repo settings\n",
        "REPO_HTTPS = \"https://github.com/TLKline/AIHC-5010-Winter-2026.git\"  # full https clone URL ending in .git\n",
        "REPO_DIR   = \"AIHC-5010-Winter-2026\"                                # folder name to clone into (or reuse)\n",
        "\n",
        "# Git settings\n",
        "BRANCH     = \"main\"                                                 # branch to commit/push to\n",
        "COMMIT_MSG = \"Update Assignment1_Colab_Workflow.ipynb from Colab test5\"    # commit message\n",
        "\n",
        "# File to overwrite inside the repo (relative to repo root)\n",
        "TARGET_REL = \"Project-1/readmit30/notebooks/Assignment1_Colab_Workflow.ipynb\"\n",
        "\n",
        "# Identity for commits\n",
        "GIT_USER_NAME  = \"Timothy Kline\"\n",
        "GIT_USER_EMAIL = \"kline.timothy@mayo.edu\"\n",
        "\n",
        "# (Optional) If you want to push to a different remote than REPO_HTTPS, set it here.\n",
        "# Leave as None to use REPO_HTTPS.\n",
        "PUSH_REMOTE_HTTPS = None  # e.g. \"https://github.com/<user>/<repo>.git\"\n",
        "\n",
        "# Set TAG_NAME to something like \"assignment1-submission-v1\".\n",
        "# Leave as \"\" (empty string) to skip tagging.\n",
        "TAG_NAME    = \"assignment1-submission-v01\"  # e.g. \"assignment1-submission-v1\"\n",
        "TAG_MESSAGE = \"Assignment 1 submission\"  # used only for annotated tags\n",
        "TAG_ANNOTATED = True  # True = annotated tag (-a -m). False = lightweight tag.\n",
        "# ==========================\n",
        "# END USER-EDITABLE SETTINGS\n",
        "# ==========================\n",
        "\n",
        "\n",
        "def run(cmd, cwd=None, check=True):\n",
        "    \"\"\"Run a shell command and stream output.\"\"\"\n",
        "    print(f\"\\n$ {' '.join(cmd)}\")\n",
        "    p = subprocess.run(cmd, cwd=cwd, text=True, capture_output=True)\n",
        "    if p.stdout:\n",
        "        print(p.stdout)\n",
        "    if p.stderr:\n",
        "        print(p.stderr)\n",
        "    if check and p.returncode != 0:\n",
        "        raise RuntimeError(f\"Command failed with exit code {p.returncode}: {' '.join(cmd)}\")\n",
        "    return p\n",
        "\n",
        "\n",
        "def github_authed_remote(https_remote: str, token: str) -> str:\n",
        "    \"\"\"\n",
        "    Convert https://github.com/OWNER/REPO.git into https://TOKEN@github.com/OWNER/REPO.git\n",
        "    Works for standard GitHub HTTPS remotes.\n",
        "    \"\"\"\n",
        "    if https_remote.startswith(\"https://\"):\n",
        "        return \"https://\" + token + \"@\" + https_remote[len(\"https://\"):]\n",
        "    raise ValueError(\"Expected an https remote URL (starting with https://).\")\n",
        "\n",
        "\n",
        "def tag_exists_locally(tag_name: str, cwd: str) -> bool:\n",
        "    p = subprocess.run([\"git\", \"tag\", \"-l\", tag_name], cwd=cwd, text=True, capture_output=True)\n",
        "    return p.stdout.strip() == tag_name\n",
        "\n",
        "\n",
        "REMOTE_FOR_PUSH = PUSH_REMOTE_HTTPS or REPO_HTTPS\n",
        "\n",
        "# 1) Clone (or reuse existing clone)\n",
        "if not os.path.isdir(REPO_DIR):\n",
        "    run([\"git\", \"clone\", REPO_HTTPS, REPO_DIR])\n",
        "else:\n",
        "    print(f\"Repo directory already exists: {REPO_DIR}\")\n",
        "\n",
        "# Ensure we're on the right branch and up-to-date\n",
        "run([\"git\", \"checkout\", BRANCH], cwd=REPO_DIR)\n",
        "run([\"git\", \"pull\", \"origin\", BRANCH], cwd=REPO_DIR)\n",
        "\n",
        "# 2) Get the currently-open notebook JSON from Colab\n",
        "nb = _message.blocking_request(\"get_ipynb\", timeout_sec=30)[\"ipynb\"]\n",
        "\n",
        "# 3) Overwrite the target file in the clone\n",
        "target_abs = os.path.join(os.getcwd(), REPO_DIR, TARGET_REL)\n",
        "os.makedirs(os.path.dirname(target_abs), exist_ok=True)\n",
        "with open(target_abs, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(nb, f, ensure_ascii=False, indent=1)\n",
        "\n",
        "print(\"Wrote current Colab notebook to:\")\n",
        "print(\" \", target_abs)\n",
        "\n",
        "# 4) Configure git identity\n",
        "run([\"git\", \"config\", \"user.name\", GIT_USER_NAME], cwd=REPO_DIR)\n",
        "run([\"git\", \"config\", \"user.email\", GIT_USER_EMAIL], cwd=REPO_DIR)\n",
        "\n",
        "# 5) Show status; if no changes, stop early\n",
        "status = run([\"git\", \"status\", \"--porcelain\"], cwd=REPO_DIR, check=True).stdout.strip()\n",
        "if not status:\n",
        "    print(\"\\nNo changes detected in the repo after writing the notebook.\")\n",
        "    print(\"Double-check that you're running this cell inside the notebook you edited,\")\n",
        "    print(\"and that TARGET_REL points to the correct path inside the repo.\")\n",
        "else:\n",
        "    # 6) Add + commit\n",
        "    run([\"git\", \"add\", TARGET_REL], cwd=REPO_DIR)\n",
        "\n",
        "    commit_proc = subprocess.run(\n",
        "        [\"git\", \"commit\", \"-m\", COMMIT_MSG],\n",
        "        cwd=REPO_DIR, text=True, capture_output=True\n",
        "    )\n",
        "    if commit_proc.stdout:\n",
        "        print(commit_proc.stdout)\n",
        "    if commit_proc.stderr:\n",
        "        print(commit_proc.stderr)\n",
        "\n",
        "    combined = (commit_proc.stdout + commit_proc.stderr).lower()\n",
        "    if commit_proc.returncode != 0 and \"nothing to commit\" not in combined:\n",
        "        raise RuntimeError(\"git commit failed unexpectedly\")\n",
        "\n",
        "    # 7) Ask for PAT and push\n",
        "    print(\"\\nEnter a GitHub Personal Access Token (PAT) with permission to push to this repo.\")\n",
        "    print(\"Recommended: fine-grained token with access to the repo and Contents: Read/Write.\")\n",
        "    token = getpass.getpass(\"GitHub PAT (input hidden): \").strip()\n",
        "    if not token:\n",
        "        raise ValueError(\"No token entered.\")\n",
        "\n",
        "    # Temporarily set authenticated remote URL for this push only (and for tag push)\n",
        "    authed_remote = github_authed_remote(REMOTE_FOR_PUSH, token)\n",
        "    run([\"git\", \"remote\", \"set-url\", \"origin\", authed_remote], cwd=REPO_DIR)\n",
        "\n",
        "    try:\n",
        "        # Push commits\n",
        "        run([\"git\", \"push\", \"origin\", BRANCH], cwd=REPO_DIR)\n",
        "        print(f\"\\n Pushed successfully to {BRANCH}.\")\n",
        "\n",
        "        # 8) OPTIONAL: Create + push tag\n",
        "        if TAG_NAME.strip():\n",
        "            tag_name = TAG_NAME.strip()\n",
        "\n",
        "            # If tag already exists locally, don't recreate\n",
        "            if tag_exists_locally(tag_name, REPO_DIR):\n",
        "                print(f\"Tag already exists locally: {tag_name}\")\n",
        "            else:\n",
        "                if TAG_ANNOTATED:\n",
        "                    run([\"git\", \"tag\", \"-a\", tag_name, \"-m\", TAG_MESSAGE], cwd=REPO_DIR)\n",
        "                else:\n",
        "                    run([\"git\", \"tag\", tag_name], cwd=REPO_DIR)\n",
        "                print(f\"Created tag: {tag_name}\")\n",
        "\n",
        "            # Push just this tag (or use --tags to push all tags)\n",
        "            run([\"git\", \"push\", \"origin\", tag_name], cwd=REPO_DIR)\n",
        "            print(f\" Pushed tag: {tag_name}\")\n",
        "        else:\n",
        "            print(\"Skipping tag creation (TAG_NAME is empty).\")\n",
        "\n",
        "        print(\"\\nDone. Check GitHub for the new commit (and tag, if set).\")\n",
        "\n",
        "    finally:\n",
        "        # Restore remote URL without token\n",
        "        run([\"git\", \"remote\", \"set-url\", \"origin\", REPO_HTTPS], cwd=REPO_DIR, check=False)\n"
      ],
      "metadata": {
        "id": "5mhiRjvTyCQ8"
      },
      "id": "5mhiRjvTyCQ8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "23",
      "metadata": {
        "id": "23"
      },
      "source": [
        "## Done ✅\n",
        "\n",
        "If you hit issues:\n",
        "- Make sure you pulled the latest course template (missing files).\n",
        "- Make sure `data/public/*` exists in your repo (or your instructor provided it separately).\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}