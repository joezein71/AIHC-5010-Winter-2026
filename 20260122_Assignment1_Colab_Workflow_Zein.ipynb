{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joezein71/AIHC-5010-Winter-2026/blob/main/20260122_Assignment1_Colab_Workflow_Zein.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0",
      "metadata": {
        "id": "0"
      },
      "source": [
        "# Assignment 1 — Colab Workflow (GitHub + Pre-commit + Submission Validation)\n",
        "\n",
        "This notebook teaches the standard workflow used throughout the course:\n",
        "\n",
        "1. Clone your team repo\n",
        "2. Install dependencies\n",
        "3. Install **pre-commit** and enable a hook to strip notebook outputs\n",
        "4. Run this notebook end-to-end\n",
        "5. Validate `predictions.csv`\n",
        "6. Commit + push + tag\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1",
      "metadata": {
        "id": "1"
      },
      "outputs": [],
      "source": [
        "# (Colab) show python and system info\n",
        "import sys, platform\n",
        "print(sys.version)\n",
        "print(platform.platform())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2",
      "metadata": {
        "id": "2"
      },
      "source": [
        "## 1) Clone Repo\n",
        "\n",
        "Login to your personal Github account, and make a fork of: https://github.com/TLKline/AIHC-5010-Winter-2026\n",
        "\n",
        "Follow setup directions for working with a PAT in GitHub (30-second guide):\n",
        "\n",
        "* Go to GitHub → Settings\n",
        "* Developer settings\n",
        "* Personal access tokens\n",
        "* Choose:\n",
        "  * Fine-Grained\n",
        "\n",
        "You can clone using HTTPS.\n",
        "\n",
        "Repo HTTPS URL (e.g., `https://github.com/TLKline/AIHC-5010-Winter-2026.git`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3",
      "metadata": {
        "id": "3"
      },
      "outputs": [],
      "source": [
        "# TODO: Change the following to your github repo path\n",
        "repo_path = 'https://github.com/joezein71/AIHC-5010-Winter-2026.git'\n",
        "!git clone {repo_path} student_repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4",
      "metadata": {
        "id": "4"
      },
      "outputs": [],
      "source": [
        "# Move into repo\n",
        "%cd student_repo\n",
        "\n",
        "# Repo git info\n",
        "!git status\n",
        "\n",
        "# Where are we?\n",
        "print('----------')\n",
        "print('We are at:')\n",
        "!pwd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5",
      "metadata": {
        "id": "5"
      },
      "source": [
        "## 2) Install dependencies\n",
        "\n",
        "This installs whatever is in `requirements.txt`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6",
      "metadata": {
        "id": "6"
      },
      "outputs": [],
      "source": [
        "!pip -q install -r Project-1/readmit30/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7",
      "metadata": {
        "id": "7"
      },
      "source": [
        "## 3) Enable pre-commit hook to strip notebook outputs\n",
        "\n",
        "This prevents giant notebooks and reduces merge/diff pain.\n",
        "\n",
        "One-time per clone:\n",
        "- `pre-commit install`\n",
        "\n",
        "After that, every `git commit` will strip outputs from `*.ipynb`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8",
      "metadata": {
        "id": "8"
      },
      "outputs": [],
      "source": [
        "!pip -q install pre-commit\n",
        "!pre-commit install\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9",
      "metadata": {
        "id": "9"
      },
      "source": [
        "#MAINSTART"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10",
      "metadata": {
        "id": "10"
      },
      "source": [
        "# 4) Submission Notebook (Template)\n",
        "\n",
        "Replace the baseline model with your team’s approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11",
      "metadata": {
        "id": "11"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "TRAIN_PATH = os.environ.get(\"TRAIN_PATH\", \"Project-1/readmit30/scripts/data/public/train.csv\")\n",
        "DEV_PATH   = os.environ.get(\"DEV_PATH\",   \"Project-1/readmit30/scripts/data/public/dev.csv\")\n",
        "TEST_PATH  = os.environ.get(\"TEST_PATH\",  \"Project-1/readmit30/scripts/data/public/public_test.csv\")\n",
        "OUT_PATH   = os.environ.get(\"OUT_PATH\",   \"predictions.csv\")\n",
        "\n",
        "print(\"TRAIN_PATH:\", TRAIN_PATH)\n",
        "print(\"DEV_PATH:\", DEV_PATH)\n",
        "print(\"TEST_PATH:\", TEST_PATH)\n",
        "print(\"OUT_PATH:\", OUT_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Also changing \"?\" and \"Unknown/Invalid\" to missing"
      ],
      "metadata": {
        "id": "EgnTAA_okp5t"
      },
      "id": "EgnTAA_okp5t"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12",
      "metadata": {
        "id": "12"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(42)\n",
        "\n",
        "train = pd.read_csv(TRAIN_PATH, na_values=['?', 'Unknown/Invalid'])\n",
        "test = pd.read_csv(TEST_PATH, na_values=['?', 'Unknown/Invalid'])\n",
        "\n",
        "assert \"row_id\" in train.columns and \"readmit30\" in train.columns\n",
        "assert \"row_id\" in test.columns\n",
        "\n",
        "X_train = train.drop(columns=[\"readmit30\"])\n",
        "y_train = train[\"readmit30\"].astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EDA Assignment**"
      ],
      "metadata": {
        "id": "SbSZWvQMio9i"
      },
      "id": "SbSZWvQMio9i"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1- Basic dataset snapshot**\n",
        "       - Rows x colums\n",
        "       - Outcomes columns names and overall readmission rate\n",
        "       - Data types summary"
      ],
      "metadata": {
        "id": "mjFgphJ5mlkp"
      },
      "id": "mjFgphJ5mlkp"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BH7YvLI-nIxW"
      },
      "id": "BH7YvLI-nIxW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f43e677d"
      },
      "source": [
        "print(f\"Dimensions of training data (train): {train.shape[0]} rows, {train.shape[1]} columns\")\n",
        "print(f\"Dimensions of training features (X_train): {X_train.shape[0]} rows, {X_train.shape[1]} columns\")\n",
        "print(f\"Dimensions of test data: {test.shape[0]} rows, {test.shape[1]} columns\")"
      ],
      "id": "f43e677d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outcomes (readmission rate at 30 days)"
      ],
      "metadata": {
        "id": "h6OlIblanboM"
      },
      "id": "h6OlIblanboM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc7d2436"
      },
      "source": [
        "overall_readmission_rate = y_train.mean()\n",
        "print(f\"Overall Readmission Rate (readmit30): {overall_readmission_rate:.4f}\")"
      ],
      "id": "cc7d2436",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Overview of Data**"
      ],
      "metadata": {
        "id": "ETCaae6z4fpN"
      },
      "id": "ETCaae6z4fpN"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f63ec547"
      },
      "source": [
        "print(\"Head of X_train (training features):\")\n",
        "display(X_train.head())"
      ],
      "id": "f63ec547",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3126589f"
      },
      "source": [
        "print(\"\\nHead of test (testing dataset):\")\n",
        "display(test.head())"
      ],
      "id": "3126589f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clarify the type of 3 variables: weight, max_glu_serum and A1CResults. It seems that these results were categorized."
      ],
      "metadata": {
        "id": "ZQiq82ZSAoYD"
      },
      "id": "ZQiq82ZSAoYD"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f59caa8"
      },
      "source": [
        "print(\"Data types for 'weight', 'max_glu_serum', and 'A1Cresult' in X_train:\")\n",
        "X_train[['weight', 'max_glu_serum', 'A1Cresult']].info()"
      ],
      "id": "5f59caa8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "881eaac7"
      },
      "source": [
        "columns_to_show_max = ['weight', 'max_glu_serum', 'A1Cresult']\n",
        "\n",
        "for col in columns_to_show_max:\n",
        "    print(f\"\\nTop 10 max values for '{col}' in X_train:\")\n",
        "    # Drop NA values, sort in descending order, and take the top 10 unique values\n",
        "    top_10_max = X_train[col].dropna().sort_values(ascending=False).unique()[:10]\n",
        "    if len(top_10_max) > 0:\n",
        "        print(top_10_max)\n",
        "    else:\n",
        "        print(\"No non-NaN values to display.\")"
      ],
      "id": "881eaac7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25da82a2"
      },
      "source": [
        "print(\"Summary Statistics for Numeric Columns in X_train:\")\n",
        "\n",
        "# Select only numeric columns\n",
        "numeric_columns = X_train.select_dtypes(include=np.number)\n",
        "\n",
        "display(numeric_columns.describe())"
      ],
      "id": "25da82a2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08b31a68"
      },
      "source": [
        "print(\"Data Types and Non-Null Counts for X_train:\")\n",
        "X_train.info()"
      ],
      "id": "08b31a68",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Types (numeric vs. categorical)\n",
        "### - change the following covariates to object variable. ID variables are better suited to be string or object variables but not integer"
      ],
      "metadata": {
        "id": "La2Byexdn3Ga"
      },
      "id": "La2Byexdn3Ga"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aac8d403"
      },
      "source": [
        "columns_to_convert = ['encounter_id', 'patient_nbr', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id', 'row_id']\n",
        "\n",
        "for col in columns_to_convert:\n",
        "    if col in X_train.columns:\n",
        "        X_train[col] = X_train[col].astype('object')\n",
        "    if col in test.columns:\n",
        "        test[col] = test[col].astype('object')\n",
        "\n",
        "print(\"Data types after conversion (X_train):\")\n",
        "X_train.info()"
      ],
      "id": "aac8d403",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e05a29a"
      },
      "source": [
        "print(\"Variable Type Stratification:\")\n",
        "print(\"-------------------------------\")\n",
        "\n",
        "continuous_vars = []\n",
        "integer_vars = []\n",
        "categorical_vars = []\n",
        "\n",
        "for col in X_train.columns:\n",
        "    dtype = X_train[col].dtype\n",
        "    if pd.api.types.is_float_dtype(dtype): # Check for float types first for continuous\n",
        "        continuous_vars.append(col)\n",
        "    elif pd.api.types.is_integer_dtype(dtype): # Check for integer types\n",
        "        integer_vars.append(col)\n",
        "    elif pd.api.types.is_object_dtype(dtype) or pd.api.types.is_categorical_dtype(dtype): # Check for object or categorical types\n",
        "        categorical_vars.append(col)\n",
        "    # We can add more specific checks for datetime if necessary, but none are identified here\n",
        "\n",
        "print(\"Continuous Variables:\")\n",
        "if continuous_vars: print(continuous_vars)\n",
        "else: print(\"None\")\n",
        "\n",
        "print(\"\\nInteger Variables:\")\n",
        "if integer_vars: print(integer_vars)\n",
        "else: print(\"None\")\n",
        "\n",
        "print(\"\\nCategorical Variables:\")\n",
        "if categorical_vars: print(categorical_vars)\n",
        "else: print(\"None\")"
      ],
      "id": "5e05a29a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Summary statistics for continuous variables"
      ],
      "metadata": {
        "id": "1Ae-JlD2pVak"
      },
      "id": "1Ae-JlD2pVak"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae3e5f6e"
      },
      "source": [
        "print(\"Summary Statistics for Numeric Columns in X_train:\")\n",
        "numeric_columns_train = X_train.select_dtypes(include=np.number)\n",
        "display(numeric_columns_train.describe())"
      ],
      "id": "ae3e5f6e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "572d8b20"
      },
      "source": [
        "print(\"\\nSummary Statistics for Numeric Columns in test data:\")\n",
        "numeric_columns_test = test.select_dtypes(include=np.number)\n",
        "display(numeric_columns_test.describe())"
      ],
      "id": "572d8b20",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Summary Statistics for categorical variables in both testing and training datasets"
      ],
      "metadata": {
        "id": "99YHbA-hpcQX"
      },
      "id": "99YHbA-hpcQX"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc5d941e"
      },
      "source": [
        "print(\"\\nSummary Statistics for Categorical Columns in X_train:\")\n",
        "categorical_columns_train = X_train.select_dtypes(include='object')\n",
        "display(categorical_columns_train.describe())"
      ],
      "id": "cc5d941e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e60777de"
      },
      "source": [
        "print(\"\\nSummary Statistics for Categorical Columns in test data:\")\n",
        "categorical_columns_test = test.select_dtypes(include='object')\n",
        "display(categorical_columns_test.describe())"
      ],
      "id": "e60777de",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2- Missingness Audit**\n",
        "      1 - A table of missingness per column: count missing and % missing, sorted high to low\n",
        "      2 - A bar plot of the top 15 columns by % missing.\n",
        "      3 - A short list:\n",
        "          - 3 columns with acceptable missingness (<5%)\n",
        "          - 3 columns with problematic missingness (>30%) and your recommended action"
      ],
      "metadata": {
        "id": "NyG5UHLuqpQa"
      },
      "id": "NyG5UHLuqpQa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1- Table of missingness per column: Count missing and % missing, sorted high to low"
      ],
      "metadata": {
        "id": "RN-rLwrvjtDB"
      },
      "id": "RN-rLwrvjtDB"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values in X_train:\")\n",
        "missing_train = X_train.isnull().sum()\n",
        "missing_train = missing_train[missing_train > 0].sort_values(ascending=False)\n",
        "if not missing_train.empty:\n",
        "    missing_train_df = pd.DataFrame(missing_train, columns=['Missing Count'])\n",
        "    missing_train_df['% Missing'] = (missing_train_df['Missing Count'] / len(X_train)) * 100\n",
        "    display(missing_train_df)\n",
        "else:\n",
        "    print(\"No missing values in X_train.\")\n",
        "\n",
        "print(\"\\nMissing values in test:\")\n",
        "missing_test = test.isnull().sum()\n",
        "missing_test = missing_test[missing_test > 0].sort_values(ascending=False)\n",
        "if not missing_test.empty:\n",
        "    missing_test_df = pd.DataFrame(missing_test, columns=['Missing Count'])\n",
        "    missing_test_df['% Missing'] = (missing_test_df['Missing Count'] / len(test)) * 100\n",
        "    display(missing_test_df)\n",
        "else:\n",
        "    print(\"No missing values in test.\")"
      ],
      "metadata": {
        "id": "oKKpLYc9joqd"
      },
      "id": "oKKpLYc9joqd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 - A bar plot of the top 15 columns by % missing:\n",
        "  - ***Only the first 10 variables in the plot include missing value. The next 5 variables were added to the plot although they do not include missing values***"
      ],
      "metadata": {
        "id": "tFsz-_LAsnlq"
      },
      "id": "tFsz-_LAsnlq"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6f6a0a1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "if 'missing_train_df' in locals() and not missing_train_df.empty:\n",
        "    # Get columns with 0% missingness\n",
        "    zero_missing_cols = X_train.columns[X_train.isnull().sum() == 0].tolist()\n",
        "\n",
        "    # Exclude columns already in missing_train_df's index\n",
        "    zero_missing_cols = [col for col in zero_missing_cols if col not in missing_train_df.index]\n",
        "\n",
        "    # Select the first 5 of these zero-missing columns (or fewer if less than 5 are available)\n",
        "    additional_cols_for_plot = zero_missing_cols[:5]\n",
        "\n",
        "    # Create a DataFrame for these additional columns with 0% missing\n",
        "    if additional_cols_for_plot:\n",
        "        additional_missing_df = pd.DataFrame({\n",
        "            'Missing Count': [0] * len(additional_cols_for_plot),\n",
        "            '% Missing': [0.0] * len(additional_cols_for_plot)\n",
        "        }, index=additional_cols_for_plot)\n",
        "\n",
        "        # Combine the original missing_train_df with the additional zero-missing columns\n",
        "        combined_missing_df = pd.concat([missing_train_df, additional_missing_df])\n",
        "    else:\n",
        "        combined_missing_df = missing_train_df\n",
        "\n",
        "    # Select the top 15 entries from the combined DataFrame\n",
        "    top_15_for_plot = combined_missing_df.head(15)\n",
        "\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    sns.barplot(x=top_15_for_plot.index, y=top_15_for_plot['% Missing'], palette='viridis', hue=top_15_for_plot.index, legend=False)\n",
        "    plt.title('Top Variables by Percentage Missingness in Training Data (including 0% missing)')\n",
        "    plt.xlabel('Variable')\n",
        "    plt.ylabel('Percentage Missing (%)')\n",
        "    plt.xticks(rotation=60, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"missing_train_df not found or is empty. Please run the missingness audit cells first.\")"
      ],
      "id": "e6f6a0a1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 - List of 3 variables with missingness <5% and 3 variables with missingness >30%\n",
        "\n",
        "      - All variables with missingness should be investigated to assess whether the is evidence that values are \"missing not at random (MNAR)\" vs. \"missing at random (MAR)\" .\n",
        "      - Values MAR with missingness < 5% should be imputed preferably using multiple imputation with methods such as \"multiple imputation by chained equations (MICE)\".\n",
        "      - imputation should not be used if missingness is not at random, or if missingness is >30%.\n",
        "    "
      ],
      "metadata": {
        "id": "ag7F4mMUu08_"
      },
      "id": "ag7F4mMUu08_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c6dcf6f"
      },
      "source": [
        "print(\"Summary of Variables by Missingness:\")\n",
        "print(\"------------------------------------\")\n",
        "\n",
        "if 'missing_train_df' in locals() and not missing_train_df.empty:\n",
        "    # Variables with <5% missingness\n",
        "    low_missing_vars = missing_train_df[missing_train_df['% Missing'] < 5].head(3)\n",
        "\n",
        "    # Variables with >30% missingness\n",
        "    high_missing_vars = missing_train_df[missing_train_df['% Missing'] > 30].head(3)\n",
        "\n",
        "    print(\"\\nVariables with <5% Missingness:\")\n",
        "    if not low_missing_vars.empty:\n",
        "        display(low_missing_vars)\n",
        "    else:\n",
        "        print(\"None found.\")\n",
        "\n",
        "    print(\"\\nVariables with >30% Missingness:\")\n",
        "    if not high_missing_vars.empty:\n",
        "        display(high_missing_vars)\n",
        "    else:\n",
        "        print(\"None found.\")\n",
        "else:\n",
        "    print(\"missing_train_df not found or is empty. Please run the missingness audit cells first.\")"
      ],
      "id": "6c6dcf6f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9619d1f"
      },
      "source": [
        "2- What is the overall value distribution for some specific variables like 'gender', 'race', 'age', and 'diag_1'?"
      ],
      "id": "b9619d1f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7aba09e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "variables_to_plot = ['gender', 'race', 'age', 'diag_1']\n",
        "\n",
        "for var in variables_to_plot:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    if var == 'diag_1': # Handle potential large number of unique values for diag_1\n",
        "        top_n = X_train[var].value_counts().nlargest(20)\n",
        "        sns.barplot(x=top_n.index, y=top_n.values)\n",
        "        plt.title(f'Top 20 Value Distribution for {var} in X_train')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "    else:\n",
        "        sns.countplot(data=X_train, x=var)\n",
        "        plt.title(f'Value Distribution for {var} in X_train')\n",
        "    plt.xlabel(var)\n",
        "    plt.ylabel('Count')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "id": "d7aba09e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2 - Is missingness related to the readmission outcomes?**"
      ],
      "metadata": {
        "id": "DmdAhFnlmTg1"
      },
      "id": "DmdAhFnlmTg1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22697cfc"
      },
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "print(\"Analyzing missingness in relation to readmission outcomes...\")\n",
        "\n",
        "# Get columns with missing values from X_train\n",
        "missing_cols_train = X_train.columns[X_train.isnull().any()].tolist()\n",
        "\n",
        "if not missing_cols_train:\n",
        "    print(\"No missing values found in X_train for analysis.\")\n",
        "else:\n",
        "    results = []\n",
        "    for col in missing_cols_train:\n",
        "        # Create a temporary DataFrame with the column, its missing indicator, and the target variable\n",
        "        temp_df = pd.DataFrame({\n",
        "            'is_missing': X_train[col].isnull(),\n",
        "            'readmit30': y_train\n",
        "        })\n",
        "\n",
        "        # Calculate counts for contingency table\n",
        "        missing_readmit_count = temp_df[(temp_df['is_missing'] == True) & (temp_df['readmit30'] == 1)].shape[0]\n",
        "        missing_non_readmit_count = temp_df[(temp_df['is_missing'] == True) & (temp_df['readmit30'] == 0)].shape[0]\n",
        "        non_missing_readmit_count = temp_df[(temp_df['is_missing'] == False) & (temp_df['readmit30'] == 1)].shape[0]\n",
        "        non_missing_non_readmit_count = temp_df[(temp_df['is_missing'] == False) & (temp_df['readmit30'] == 0)].shape[0]\n",
        "\n",
        "        # Calculate the average readmit30 rate for missing and non-missing groups\n",
        "        missing_readmit_rate = temp_df[temp_df['is_missing'] == True]['readmit30'].mean()\n",
        "        non_missing_readmit_rate = temp_df[temp_df['is_missing'] == False]['readmit30'].mean()\n",
        "\n",
        "        p_value = np.nan\n",
        "        # Perform Chi-squared test if there are enough observations in each category\n",
        "        if (missing_readmit_count + missing_non_readmit_count > 0) and \\\n",
        "           (non_missing_readmit_count + non_missing_non_readmit_count > 0) and \\\n",
        "           (missing_readmit_count + non_missing_readmit_count > 0) and \\\n",
        "           (missing_non_readmit_count + non_missing_non_readmit_count > 0):\n",
        "            contingency_table = [\n",
        "                [missing_readmit_count, missing_non_readmit_count],\n",
        "                [non_missing_readmit_count, non_missing_non_readmit_count]\n",
        "            ]\n",
        "            # Only perform chi2_contingency if all expected frequencies are >= 5\n",
        "            # This is a common rule of thumb for the validity of the chi-squared test\n",
        "            try:\n",
        "                chi2, p, _, expected = stats.chi2_contingency(contingency_table)\n",
        "                if np.all(expected >= 5):\n",
        "                    p_value = p\n",
        "            except ValueError: # Occurs if table dimensions are zero or contain NaNs\n",
        "                pass\n",
        "\n",
        "        results.append({\n",
        "            'Column': col,\n",
        "            'Missing Readmit Rate': missing_readmit_rate,\n",
        "            'Non-Missing Readmit Rate': non_missing_readmit_rate,\n",
        "            'P-value': p_value\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    display(results_df.sort_values(by='Missing Readmit Rate', ascending=False))\n",
        "\n",
        "    print(\"\\nInterpretation: If 'Missing Readmit Rate' is significantly different from 'Non-Missing Readmit Rate' for a given column, then missingness in that column might be related to readmission outcomes. A small P-value (e.g., < 0.05) suggests that the observed difference is statistically significant.\")"
      ],
      "id": "22697cfc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e86e795"
      },
      "source": [
        "The table above shows the readmission rates when a particular feature is missing versus when it is present. A substantial difference between these two rates could indicate that the missingness itself provides information about the readmission outcome. For instance, if the 'Missing Readmit Rate' for a column is much higher than its 'Non-Missing Readmit Rate', it suggests that patients for whom that data point is absent might have a higher propensity for readmission. This can be a form of *informative missingness*."
      ],
      "id": "6e86e795"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - Is missingness related to outcomes? Analysis of 3 specific variables with missingness >15%"
      ],
      "metadata": {
        "id": "gnCAVntZxe1_"
      },
      "id": "gnCAVntZxe1_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab04fa4b"
      },
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "print(\"Analyzing readmission rates based on missingness indicators:\")\n",
        "\n",
        "variables_to_analyze = ['payer_code', 'medical_specialty', 'A1Cresult']\n",
        "\n",
        "results_missing_indicators = []\n",
        "\n",
        "for col in variables_to_analyze:\n",
        "    # Create the binary indicator for missingness\n",
        "    X_train[f'is_missing_{col}'] = X_train[col].isnull().astype(int)\n",
        "\n",
        "    # Calculate counts for contingency table\n",
        "    missing_readmit_count = y_train[X_train[f'is_missing_{col}'] == 1].sum()\n",
        "    missing_non_readmit_count = (X_train[f'is_missing_{col}'] == 1).sum() - missing_readmit_count\n",
        "    non_missing_readmit_count = y_train[X_train[f'is_missing_{col}'] == 0].sum()\n",
        "    non_missing_non_readmit_count = (X_train[f'is_missing_{col}'] == 0).sum() - non_missing_readmit_count\n",
        "\n",
        "    # Calculate readmission rate for missing vs. not missing\n",
        "    readmit_rate_missing = y_train[X_train[f'is_missing_{col}'] == 1].mean()\n",
        "    readmit_rate_not_missing = y_train[X_train[f'is_missing_{col}'] == 0].mean()\n",
        "\n",
        "    p_value = np.nan\n",
        "    # Perform Chi-squared test if there are enough observations in each category\n",
        "    if (missing_readmit_count + missing_non_readmit_count > 0) and \\\n",
        "       (non_missing_readmit_count + non_missing_non_readmit_count > 0) and \\\n",
        "       (missing_readmit_count + non_missing_readmit_count > 0) and \\\n",
        "       (missing_non_readmit_count + non_missing_non_readmit_count > 0):\n",
        "        contingency_table = [\n",
        "            [missing_readmit_count, missing_non_readmit_count],\n",
        "            [non_missing_readmit_count, non_missing_non_readmit_count]\n",
        "        ]\n",
        "        try:\n",
        "            chi2, p, _, expected = stats.chi2_contingency(contingency_table)\n",
        "            # Common rule of thumb for chi-squared validity: all expected frequencies >= 5\n",
        "            if np.all(expected >= 5):\n",
        "                p_value = p\n",
        "        except ValueError: # Occurs if table dimensions are zero or contain NaNs\n",
        "            pass\n",
        "\n",
        "    results_missing_indicators.append({\n",
        "        'Variable': col,\n",
        "        'Readmission Rate (Missing)': readmit_rate_missing,\n",
        "        'Readmission Rate (Not Missing)': non_missing_readmit_rate,\n",
        "        'P-value': p_value\n",
        "    })\n",
        "\n",
        "results_df_indicators = pd.DataFrame(results_missing_indicators)\n",
        "display(results_df_indicators)\n",
        "\n",
        "print(\"\\nInterpretation: A significant difference between 'Readmission Rate (Missing)' and 'Readmission Rate (Not Missing)' for a variable suggests that the missingness itself might be an important predictor. A small P-value (e.g., < 0.05) suggests that the observed difference is statistically significant.\")\n",
        "\n",
        "# Drop the temporary indicator columns to keep X_train clean for subsequent steps, if any.\n",
        "# Or keep them if they are intended for feature engineering.\n",
        "for col in variables_to_analyze:\n",
        "    X_train = X_train.drop(columns=[f'is_missing_{col}'])"
      ],
      "id": "ab04fa4b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *A significant difference (p< 0.05) between 'Readmission Rate (Missing)' and 'Readmission Rate (Not Missing)' for a variable suggests that the missingness itself might be an important predictor for readmission.*"
      ],
      "metadata": {
        "id": "2K9tp90Dy8As"
      },
      "id": "2K9tp90Dy8As"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4- Minimal data quality check**\n",
        "     1- Dublicates\n",
        "     2- Outliers / Validity\n",
        "     3- leakage screen"
      ],
      "metadata": {
        "id": "n4_7cbT40iHn"
      },
      "id": "n4_7cbT40iHn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d75481d1"
      },
      "source": [
        "# **4- Minimal data quality check**\n",
        "     1- Dublicates\n",
        "     2- Outliers / Validity\n",
        "     3- leakage screen"
      ],
      "id": "d75481d1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.1 Duplicates**"
      ],
      "metadata": {
        "id": "eLZyDstS1g3t"
      },
      "id": "eLZyDstS1g3t"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yspn7RaF1nrI"
      },
      "id": "Yspn7RaF1nrI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.1 Description of the types of variables in the data"
      ],
      "metadata": {
        "id": "iSWuNY6bmATf"
      },
      "id": "iSWuNY6bmATf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13",
      "metadata": {
        "id": "13"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "# TODO: Add any new imports for your own method here\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "method = 4\n",
        "\n",
        "cat_cols = [c for c in X_train.columns if X_train[c].dtype == \"object\"]\n",
        "num_cols = [c for c in X_train.columns if c not in cat_cols]\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))]), num_cols),\n",
        "        (\"cat\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "                          (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))]), cat_cols),\n",
        "    ],\n",
        ")\n",
        "\n",
        "if method==1:\n",
        "    # Use logistic regression model\n",
        "    clf = Pipeline([\n",
        "        (\"preprocess\", preprocess),\n",
        "        (\"model\", LogisticRegression(max_iter=200)),\n",
        "    ])\n",
        "\n",
        "if method==2:\n",
        "    # Use logistic regression model\n",
        "    clf = Pipeline([\n",
        "        (\"preprocess\", preprocess),\n",
        "        (\"model\", LogisticRegression(max_iter=200,class_weight='balanced')),\n",
        "    ])\n",
        "\n",
        "if method==3:\n",
        "    # Use SVC (i.e. SVM model)\n",
        "    clf = Pipeline(\n",
        "        [\n",
        "            (\"preprocess\", preprocess),\n",
        "            (\"scaler\", StandardScaler(with_mean=False)), # Add StandardScaler here\n",
        "            (\"model\", SVC(gamma=\"auto\",max_iter=1000,probability=True)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "if method == 4:\n",
        "    # Preprocess for HGB: ordinal-encode categories (HGB needs numeric inputs)\n",
        "    preprocess_hgb = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", Pipeline([\n",
        "                (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "            ]), num_cols),\n",
        "            (\"cat\", Pipeline([\n",
        "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "                (\"ord\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)),\n",
        "            ]), cat_cols),\n",
        "        ],\n",
        "        remainder=\"drop\",\n",
        "    )\n",
        "\n",
        "    clf = Pipeline([\n",
        "        (\"preprocess\", preprocess_hgb),\n",
        "        (\"model\", HistGradientBoostingClassifier(\n",
        "            max_depth=6,\n",
        "            learning_rate=0.05,\n",
        "            max_iter=300,\n",
        "            l2_regularization=1.0,\n",
        "            early_stopping=True,\n",
        "            random_state=42,\n",
        "            class_weight='balanced',\n",
        "        )),\n",
        "    ])\n",
        "\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14",
      "metadata": {
        "id": "14"
      },
      "outputs": [],
      "source": [
        "p_test = clf.predict_proba(test)[:, 1]\n",
        "pred = pd.DataFrame({\"row_id\": test[\"row_id\"].astype(int), \"prob_readmit30\": p_test.astype(float)})\n",
        "pred.to_csv(OUT_PATH, index=False)\n",
        "pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15",
      "metadata": {
        "id": "15"
      },
      "outputs": [],
      "source": [
        "# Validate output format (required for students before tagging)\n",
        "!python Project-1/readmit30/scripts/validate_submission.py --pred {OUT_PATH} --test {TEST_PATH}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16",
      "metadata": {
        "id": "16"
      },
      "outputs": [],
      "source": [
        "# Calculate metrics for the dev set\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dev = pd.read_csv(DEV_PATH)\n",
        "\n",
        "X_dev = dev.drop(columns=[\"readmit30\"])\n",
        "y_dev = dev[\"readmit30\"].astype(int)\n",
        "\n",
        "# Calculate metrics\n",
        "y_true = y_dev.astype(int)\n",
        "y_pred = clf.predict_proba(X_dev)[:, 1]\n",
        "\n",
        "auroc = roc_auc_score(y_true, y_pred)\n",
        "auprc = average_precision_score(y_true, y_pred)\n",
        "brier = brier_score_loss(y_true, y_pred)\n",
        "\n",
        "print(f'AUROC: {auroc:.4f}')\n",
        "print(f'AUPRC: {auprc:.4f}')\n",
        "print(f'Brier Score: {brier:.4f}')\n",
        "\n",
        "# Create figures\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Histogram of predicted probabilities\n",
        "plt.hist(y_pred, bins=20, alpha=0.7, label='Predicted Probabilities')\n",
        "plt.title('Histogram of Predicted Probabilities')\n",
        "plt.xlabel('Probability')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Scatter plot of true vs predicted\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_true, y_pred, alpha=0.5, label='True vs Predicted')\n",
        "plt.title('True vs Predicted Probabilities')\n",
        "plt.xlabel('True Labels')\n",
        "plt.ylabel('Predicted Probabilities')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Create ROC Curve\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fpr, tpr, label=f'AUROC = {auroc:.4f}')\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
        "plt.title('ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Create Precision-Recall Curve\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(recall, precision, label=f'AUPRC = {auprc:.4f}')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Create Confusion Matrix Heatmap\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "threshold = 0.5  # Default threshold for binary classification\n",
        "y_pred_binary = (y_pred >= threshold).astype(int)\n",
        "cm = confusion_matrix(y_true, y_pred_binary)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Readmit', 'Readmit'], yticklabels=['No Readmit', 'Readmit'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17",
      "metadata": {
        "id": "17"
      },
      "source": [
        "#MAINEND"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18",
      "metadata": {
        "id": "18"
      },
      "source": [
        "## 5) Validate the predictions file format\n",
        "\n",
        "This checks:\n",
        "- required columns\n",
        "- probabilities in [0, 1]\n",
        "- row_ids match the test file\n",
        "\n",
        "It assumes the submission notebook wrote `predictions.csv` in the repo root.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19",
      "metadata": {
        "id": "19"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "pred_path = Path(\"predictions.csv\")\n",
        "test_path = Path(\"Project-1/readmit30/scripts/data/public/public_test.csv\")\n",
        "\n",
        "if not pred_path.exists():\n",
        "    print(\"predictions.csv not found. Run notebooks/submission.ipynb first.\")\n",
        "else:\n",
        "    !python Project-1/readmit30/scripts/validate_submission.py --pred predictions.csv --test Project-1/readmit30/scripts/data/public/public_test.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20",
      "metadata": {
        "id": "20"
      },
      "source": [
        "## 6) Commit + push + tag\n",
        "\n",
        "You will:\n",
        "- add changes\n",
        "- commit (pre-commit hook runs here)\n",
        "- push\n",
        "- tag a milestone (example: `milestone_wk3`) and push tags\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21",
      "metadata": {
        "id": "21"
      },
      "source": [
        "You will need a Personal Access Token (PAT) for the following step. See instructions above."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Colab -> GitHub commit/push for a specific notebook path (PAT auth) ====\n",
        "# What this does:\n",
        "#  1) clones the repo into the Colab VM\n",
        "#  2) overwrites the target notebook file with the *currently open* Colab notebook\n",
        "#  3) commits the change\n",
        "#  4) asks you for a GitHub PAT and pushes to the target branch\n",
        "#  5) (optional) creates a git tag and pushes the tag\n",
        "#\n",
        "# Notes:\n",
        "#  - PAT is read via getpass (not echoed). It is only used for this runtime session.\n",
        "#  - This overwrites the file at TARGET_REL with the *current Colab notebook contents*.\n",
        "\n",
        "import os\n",
        "import json\n",
        "import subprocess\n",
        "import getpass\n",
        "from google.colab import _message\n",
        "\n",
        "# ==========================\n",
        "# START USER-EDITABLE SETTINGS\n",
        "# ==========================\n",
        "# Repo settings\n",
        "REPO_HTTPS = \"https://github.com/TLKline/AIHC-5010-Winter-2026.git\"  # full https clone URL ending in .git\n",
        "REPO_DIR   = \"AIHC-5010-Winter-2026\"                                # folder name to clone into (or reuse)\n",
        "\n",
        "# Git settings\n",
        "BRANCH     = \"main\"                                                 # branch to commit/push to\n",
        "COMMIT_MSG = \"Update Assignment1_Colab_Workflow.ipynb from Colab test5\"    # commit message\n",
        "\n",
        "# File to overwrite inside the repo (relative to repo root)\n",
        "TARGET_REL = \"Project-1/readmit30/notebooks/Assignment1_Colab_Workflow.ipynb\"\n",
        "\n",
        "# Identity for commits\n",
        "GIT_USER_NAME  = \"Timothy Kline\"\n",
        "GIT_USER_EMAIL = \"kline.timothy@mayo.edu\"\n",
        "\n",
        "# (Optional) If you want to push to a different remote than REPO_HTTPS, set it here.\n",
        "# Leave as None to use REPO_HTTPS.\n",
        "PUSH_REMOTE_HTTPS = None  # e.g. \"https://github.com/<user>/<repo>.git\"\n",
        "\n",
        "# Set TAG_NAME to something like \"assignment1-submission-v1\".\n",
        "# Leave as \"\" (empty string) to skip tagging.\n",
        "TAG_NAME    = \"assignment1-submission-v01\"  # e.g. \"assignment1-submission-v1\"\n",
        "TAG_MESSAGE = \"Assignment 1 submission\"  # used only for annotated tags\n",
        "TAG_ANNOTATED = True  # True = annotated tag (-a -m). False = lightweight tag.\n",
        "# ==========================\n",
        "# END USER-EDITABLE SETTINGS\n",
        "# ==========================\n",
        "\n",
        "\n",
        "def run(cmd, cwd=None, check=True):\n",
        "    \"\"\"Run a shell command and stream output.\"\"\"\n",
        "    print(f\"\\n$ {' '.join(cmd)}\")\n",
        "    p = subprocess.run(cmd, cwd=cwd, text=True, capture_output=True)\n",
        "    if p.stdout:\n",
        "        print(p.stdout)\n",
        "    if p.stderr:\n",
        "        print(p.stderr)\n",
        "    if check and p.returncode != 0:\n",
        "        raise RuntimeError(f\"Command failed with exit code {p.returncode}: {' '.join(cmd)}\")\n",
        "    return p\n",
        "\n",
        "\n",
        "def github_authed_remote(https_remote: str, token: str) -> str:\n",
        "    \"\"\"\n",
        "    Convert https://github.com/OWNER/REPO.git into https://TOKEN@github.com/OWNER/REPO.git\n",
        "    Works for standard GitHub HTTPS remotes.\n",
        "    \"\"\"\n",
        "    if https_remote.startswith(\"https://\"):\n",
        "        return \"https://\" + token + \"@\" + https_remote[len(\"https://\"):]\n",
        "    raise ValueError(\"Expected an https remote URL (starting with https://).\")\n",
        "\n",
        "\n",
        "def tag_exists_locally(tag_name: str, cwd: str) -> bool:\n",
        "    p = subprocess.run([\"git\", \"tag\", \"-l\", tag_name], cwd=cwd, text=True, capture_output=True)\n",
        "    return p.stdout.strip() == tag_name\n",
        "\n",
        "\n",
        "REMOTE_FOR_PUSH = PUSH_REMOTE_HTTPS or REPO_HTTPS\n",
        "\n",
        "# 1) Clone (or reuse existing clone)\n",
        "if not os.path.isdir(REPO_DIR):\n",
        "    run([\"git\", \"clone\", REPO_HTTPS, REPO_DIR])\n",
        "else:\n",
        "    print(f\"Repo directory already exists: {REPO_DIR}\")\n",
        "\n",
        "# Ensure we're on the right branch and up-to-date\n",
        "run([\"git\", \"checkout\", BRANCH], cwd=REPO_DIR)\n",
        "run([\"git\", \"pull\", \"origin\", BRANCH], cwd=REPO_DIR)\n",
        "\n",
        "# 2) Get the currently-open notebook JSON from Colab\n",
        "nb = _message.blocking_request(\"get_ipynb\", timeout_sec=30)[\"ipynb\"]\n",
        "\n",
        "# 3) Overwrite the target file in the clone\n",
        "target_abs = os.path.join(os.getcwd(), REPO_DIR, TARGET_REL)\n",
        "os.makedirs(os.path.dirname(target_abs), exist_ok=True)\n",
        "with open(target_abs, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(nb, f, ensure_ascii=False, indent=1)\n",
        "\n",
        "print(\"Wrote current Colab notebook to:\")\n",
        "print(\" \", target_abs)\n",
        "\n",
        "# 4) Configure git identity\n",
        "run([\"git\", \"config\", \"user.name\", GIT_USER_NAME], cwd=REPO_DIR)\n",
        "run([\"git\", \"config\", \"user.email\", GIT_USER_EMAIL], cwd=REPO_DIR)\n",
        "\n",
        "# 5) Show status; if no changes, stop early\n",
        "status = run([\"git\", \"status\", \"--porcelain\"], cwd=REPO_DIR, check=True).stdout.strip()\n",
        "if not status:\n",
        "    print(\"\\nNo changes detected in the repo after writing the notebook.\")\n",
        "    print(\"Double-check that you're running this cell inside the notebook you edited,\")\n",
        "    print(\"and that TARGET_REL points to the correct path inside the repo.\")\n",
        "else:\n",
        "    # 6) Add + commit\n",
        "    run([\"git\", \"add\", TARGET_REL], cwd=REPO_DIR)\n",
        "\n",
        "    commit_proc = subprocess.run(\n",
        "        [\"git\", \"commit\", \"-m\", COMMIT_MSG],\n",
        "        cwd=REPO_DIR, text=True, capture_output=True\n",
        "    )\n",
        "    if commit_proc.stdout:\n",
        "        print(commit_proc.stdout)\n",
        "    if commit_proc.stderr:\n",
        "        print(commit_proc.stderr)\n",
        "\n",
        "    combined = (commit_proc.stdout + commit_proc.stderr).lower()\n",
        "    if commit_proc.returncode != 0 and \"nothing to commit\" not in combined:\n",
        "        raise RuntimeError(\"git commit failed unexpectedly\")\n",
        "\n",
        "    # 7) Ask for PAT and push\n",
        "    print(\"\\nEnter a GitHub Personal Access Token (PAT) with permission to push to this repo.\")\n",
        "    print(\"Recommended: fine-grained token with access to the repo and Contents: Read/Write.\")\n",
        "    token = getpass.getpass(\"GitHub PAT (input hidden): \").strip()\n",
        "    if not token:\n",
        "        raise ValueError(\"No token entered.\")\n",
        "\n",
        "    # Temporarily set authenticated remote URL for this push only (and for tag push)\n",
        "    authed_remote = github_authed_remote(REMOTE_FOR_PUSH, token)\n",
        "    run([\"git\", \"remote\", \"set-url\", \"origin\", authed_remote], cwd=REPO_DIR)\n",
        "\n",
        "    try:\n",
        "        # Push commits\n",
        "        run([\"git\", \"push\", \"origin\", BRANCH], cwd=REPO_DIR)\n",
        "        print(f\"\\n Pushed successfully to {BRANCH}.\")\n",
        "\n",
        "        # 8) OPTIONAL: Create + push tag\n",
        "        if TAG_NAME.strip():\n",
        "            tag_name = TAG_NAME.strip()\n",
        "\n",
        "            # If tag already exists locally, don't recreate\n",
        "            if tag_exists_locally(tag_name, REPO_DIR):\n",
        "                print(f\"Tag already exists locally: {tag_name}\")\n",
        "            else:\n",
        "                if TAG_ANNOTATED:\n",
        "                    run([\"git\", \"tag\", \"-a\", tag_name, \"-m\", TAG_MESSAGE], cwd=REPO_DIR)\n",
        "                else:\n",
        "                    run([\"git\", \"tag\", tag_name], cwd=REPO_DIR)\n",
        "                print(f\"Created tag: {tag_name}\")\n",
        "\n",
        "            # Push just this tag (or use --tags to push all tags)\n",
        "            run([\"git\", \"push\", \"origin\", tag_name], cwd=REPO_DIR)\n",
        "            print(f\" Pushed tag: {tag_name}\")\n",
        "        else:\n",
        "            print(\"Skipping tag creation (TAG_NAME is empty).\")\n",
        "\n",
        "        print(\"\\nDone. Check GitHub for the new commit (and tag, if set).\")\n",
        "\n",
        "    finally:\n",
        "        # Restore remote URL without token\n",
        "        run([\"git\", \"remote\", \"set-url\", \"origin\", REPO_HTTPS], cwd=REPO_DIR, check=False)\n"
      ],
      "metadata": {
        "id": "5mhiRjvTyCQ8"
      },
      "id": "5mhiRjvTyCQ8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "23",
      "metadata": {
        "id": "23"
      },
      "source": [
        "## Done ✅\n",
        "\n",
        "If you hit issues:\n",
        "- Make sure you pulled the latest course template (missing files).\n",
        "- Make sure `data/public/*` exists in your repo (or your instructor provided it separately).\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}